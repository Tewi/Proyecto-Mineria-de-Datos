{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto CC5206\n",
    "\n",
    "Mineria de datos sobre datasets del banco mundial. Eliminar ultimas filas del excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar librerias y dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Series Name</th>\n",
       "      <th>Series Code</th>\n",
       "      <th>2016 [YR2016]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>2005 PPP conversion factor, GDP (LCU per inter...</td>\n",
       "      <td>PA.NUS.PPP.05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>2005 PPP conversion factor, private consumptio...</td>\n",
       "      <td>PA.NUS.PRVT.PP.05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Access to clean fuels and technologies for coo...</td>\n",
       "      <td>EG.CFT.ACCS.ZS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Access to electricity (% of population)</td>\n",
       "      <td>EG.ELC.ACCS.ZS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Access to electricity, rural (% of rural popul...</td>\n",
       "      <td>EG.ELC.ACCS.RU.ZS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country Name Country Code  \\\n",
       "0  Afghanistan          AFG   \n",
       "1  Afghanistan          AFG   \n",
       "2  Afghanistan          AFG   \n",
       "3  Afghanistan          AFG   \n",
       "4  Afghanistan          AFG   \n",
       "\n",
       "                                         Series Name        Series Code  \\\n",
       "0  2005 PPP conversion factor, GDP (LCU per inter...      PA.NUS.PPP.05   \n",
       "1  2005 PPP conversion factor, private consumptio...  PA.NUS.PRVT.PP.05   \n",
       "2  Access to clean fuels and technologies for coo...     EG.CFT.ACCS.ZS   \n",
       "3            Access to electricity (% of population)     EG.ELC.ACCS.ZS   \n",
       "4  Access to electricity, rural (% of rural popul...  EG.ELC.ACCS.RU.ZS   \n",
       "\n",
       "   2016 [YR2016]  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdb\n",
    "\n",
    "data = pd.read_excel('jobs.xlsx')\n",
    "dev_2016 = pd.read_excel('development_2016.xlsx')\n",
    "\n",
    "dev_2016.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajustar Formato de la Tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Eliminar Columnas que no ser√°n utilizadas\n",
    "data.__delitem__('Series Code')\n",
    "dev_2016.__delitem__('Series Code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The numpy boolean negative, the `-` operator, is not supported, use the `~` operator or the logical_not function instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a35044eb8f27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mxvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m#values = values+xvals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnegative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;31m#not np.isnan(d_2016[c_feature].all()):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mcolumns_d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: The numpy boolean negative, the `-` operator, is not supported, use the `~` operator or the logical_not function instead."
     ]
    }
   ],
   "source": [
    "#El metodo np.unique ordena las listas \n",
    "#es necesario devolver la lista a su orden original\n",
    "#===================================================\n",
    "paises_d = np.array(dev_2016['Country Name'])\n",
    "indexes_d = np.unique(paises_d, return_index=True)[1]\n",
    "paises_d = [paises_d[index] for index in sorted(indexes_d)]\n",
    "\n",
    "features_d = np.array(dev_2016['Series Name'])\n",
    "indexes_d = np.unique(features_d, return_index=True)[1]\n",
    "features_d = [features_d[index] for index in sorted(indexes_d)]\n",
    "\n",
    "codes_d = np.array(dev_2016['Country Code'])\n",
    "indexes_d = np.unique(codes_d, return_index=True)[1]\n",
    "codes_d = [codes_d[index] for index in sorted(indexes_d)]\n",
    "\n",
    "#====================================================\n",
    "\n",
    "columns_d = [('Country Name',paises_d),('Country Code',codes_d)]\n",
    "empty = 0\n",
    "notempty = 0\n",
    "for c_feature in features_d:\n",
    "    #print c_feature\n",
    "    #values = []\n",
    "    #values.append(c_feature)\n",
    "    vals = dev_2016[dev_2016['Series Name'] == c_feature]['2016 [YR2016]']\n",
    "    xvals = vals.tolist()\n",
    "    #values = values+xvals\n",
    "    if np.negative(np.isnan(np.array(xvals))).any():\n",
    "    #not np.isnan(d_2016[c_feature].all()):\n",
    "        columns_d.append((c_feature,xvals))\n",
    "        notempty+=1\n",
    "    else:\n",
    "        #print c_feature+\" = Duarte\"\n",
    "        empty+=1\n",
    "\n",
    "      \n",
    "d_2016 = pd.DataFrame.from_items(columns_d)\n",
    "d_2016.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#El metodo np.unique ordena las listas \n",
    "#es necesario devolver la lista a su orden original\n",
    "#===================================================\n",
    "paises = np.array(data['Country Name'])\n",
    "indexes = np.unique(paises, return_index=True)[1]\n",
    "paises = [paises[index] for index in sorted(indexes)]\n",
    "\n",
    "caracteristicas = np.array(data['Series Name'])\n",
    "indexes = np.unique(caracteristicas, return_index=True)[1]\n",
    "caracteristicas = [caracteristicas[index] for index in sorted(indexes)]\n",
    "\n",
    "codigos = np.array(data['Country Code'])\n",
    "indexes = np.unique(codigos, return_index=True)[1]\n",
    "codigos = [codigos[index] for index in sorted(indexes)]\n",
    "\n",
    "#====================================================\n",
    "\n",
    "columnas = [('Country Name',paises),('Country Code',codigos)]\n",
    "\n",
    "for i in range(len(caracteristicas)):\n",
    "    car = caracteristicas[i]\n",
    "    count = 0\n",
    "    nans = 0\n",
    "    values = []\n",
    "    while count<len(paises):\n",
    "        ind = i+count*len(caracteristicas)\n",
    "        val = data['Most Recent Value [YR20111]'][ind]\n",
    "        if '..' == val:\n",
    "            xval = np.nan\n",
    "            nans += 1\n",
    "        else:\n",
    "            xval = float(val)\n",
    "        values.append(xval)\n",
    "        count+=1\n",
    "    if nans != count:\n",
    "        columnas.append((car,values))\n",
    "      \n",
    "xdata = pd.DataFrame.from_items(columnas)\n",
    "xdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminar Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#'''\n",
    "outliers1 = [u'High income', u'High income: OECD', u'OECD members', u'World']\n",
    "outliers2 = [u'East Asia & Pacific',u'East Asia & Pacific (excluding high income)',\n",
    " u'Euro area',u'Europe & Central Asia',u'European Union',u'Low & middle income',\n",
    " u'Middle income',u'North America',u'Upper middle income']\n",
    "\n",
    "outliers3 = [u'Arab World', u'Sub-Saharan Africa',\n",
    "             u'Sub-Saharan Africa (excluding high income)', u'Middle East & North Africa',\n",
    "             u'Middle East & North Africa (excluding high income)', \n",
    "             u'Latin America & Caribbean',u'Latin America & Caribbean (excluding high income)',\n",
    "             u'Least developed countries: UN classification', \n",
    "             u'Heavily indebted poor countries (HIPC)',u'High income',u'High income: nonOECD',\n",
    "             u'High income: OECD', u'Euro area',u'Europe & Central Asia',\n",
    "             u'Europe & Central Asia (excluding high income)',u'European Union',\n",
    "             u'East Asia & Pacific',u'East Asia & Pacific (excluding high income)',\n",
    "             u'Lower middle income',u'South Asia']\n",
    "\n",
    "for out in outliers1:\n",
    "    xdata = xdata[xdata['Country Name'] != out]\n",
    "    \n",
    "for out in outliers2:\n",
    "    xdata = xdata[xdata['Country Name'] != out]\n",
    "    \n",
    "for out in outliers3:\n",
    "    xdata = xdata[xdata['Country Name'] != out]\n",
    " \n",
    "paises = xdata['Country Name'].values.tolist()\n",
    "\n",
    "#xdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis Estadistico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "varianzas = []\n",
    "promedios = []\n",
    "maximos = []\n",
    "minimos = []\n",
    "desv = []\n",
    "for k in range(2,len(d_2016.keys())):\n",
    "    \n",
    "    llave = d_2016.keys()[k]\n",
    "    valores = d_2016[llave] \n",
    "    count = 0\n",
    "    \n",
    "    #print llave\n",
    "    xmean = np.nanmean(valores)\n",
    "    xmin = np.nanmin(valores)\n",
    "    xmax = np.nanmax(valores)\n",
    "    xstd = np.nanstd(valores)\n",
    "    xvar = np.nanvar(valores)\n",
    "    \n",
    "    promedios.append(xmean)\n",
    "    minimos.append(xmin)\n",
    "    maximos.append(xmax)\n",
    "    desv.append(xstd)\n",
    "    varianzas.append(xvar)\n",
    "    \n",
    "sort = np.sort(varianzas)\n",
    "most = -2   \n",
    "\n",
    "print \"Estadisticas con mayor varianza:\"\n",
    "for i in range(10):\n",
    "    j = np.argwhere(varianzas == sort[most])\n",
    "    k = sort[most]\n",
    "    print str(i+1)+' '+features_d[j]+' ('+str(sort[most]) #+')\\n'\n",
    "    most-=1\n",
    "\n",
    "#promedios\n",
    "#xdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xdata=d_2016\n",
    "varianzas = []\n",
    "promedios = []\n",
    "maximos = []\n",
    "minimos = []\n",
    "desv = []\n",
    "for k in range(2,len(xdata.keys())):\n",
    "    \n",
    "    llave = xdata.keys()[k]\n",
    "    valores = xdata[llave] \n",
    "    count = 0\n",
    "    \n",
    "    #print llave\n",
    "    xmean = np.nanmean(valores)\n",
    "    xmin = np.nanmin(valores)\n",
    "    xmax = np.nanmax(valores)\n",
    "    xstd = np.nanstd(valores)\n",
    "    xvar = np.nanvar(valores)\n",
    "    \n",
    "    promedios.append(xmean)\n",
    "    minimos.append(xmin)\n",
    "    maximos.append(xmax)\n",
    "    desv.append(xstd)\n",
    "    varianzas.append(xvar)\n",
    "    \n",
    "sort = np.sort(varianzas)\n",
    "most = -1   \n",
    "\n",
    "print \"Estadisticas con mayor varianza:\"\n",
    "for i in range(10):\n",
    "    j = np.argwhere(varianzas == sort[most])\n",
    "    k = sort[most]\n",
    "    pdb.set_trace()\n",
    "    print str(i+1)+' '+caracteristicas[j]     #+' ('+str(sort[most])')\n",
    "    most-=1\n",
    "\n",
    "#promedios\n",
    "#sort\n",
    "#xdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "x = []\n",
    "for nonan in xdata['Population ages 0-14, total']:\n",
    "#for nonan in xdata['Self-employed, male (% of males employed)']:\n",
    "    if not np.isnan(nonan):\n",
    "        x.append(nonan)\n",
    "\n",
    "ax1.hist(x, 5, facecolor='green', alpha=0.75)\n",
    "\n",
    "ax1.set_xlabel('Population ages 0-14')\n",
    "ax1.set_ylabel('Total')\n",
    "#ax1.title('Histograma')\n",
    "\n",
    "#plt.add_subplot(212, facecolor='r')\n",
    "x =[]\n",
    "for nonan in xdata['Self-employed, male (% of males employed)']:\n",
    "    if not np.isnan(nonan):\n",
    "        x.append(nonan)\n",
    "\n",
    "ax2.hist(x, 5, facecolor='blue', alpha=0.75)\n",
    "\n",
    "ax2.set_xlabel('Self-employed, male')\n",
    "ax2.set_ylabel('% of males employed')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_df = xdata.as_matrix()\n",
    "test = np_df[:,2:]\n",
    "for row in range(test.shape[0]):\n",
    "    for column in range(test.shape[1]):\n",
    "        val = test[row][column]\n",
    "        if np.isnan(val):\n",
    "\n",
    "            test[row][column]= promedios[column] #meanx #0 #fixed.data[0]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "xdf = pd.DataFrame(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_df = d_2016.as_matrix()\n",
    "test = np_df[:,2:]\n",
    "for row in range(test.shape[0]):\n",
    "    for column in range(test.shape[1]):\n",
    "        val = test[row][column]\n",
    "        #print val\n",
    "        if np.isnan(val):\n",
    "\n",
    "            test[row][column]= promedios[column] #meanx #0 #fixed.data[0]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "xdf = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectors = []\n",
    "tot = test#.T\n",
    "for i in range(len(tot[:,0])):\n",
    "    vectors.append(tot[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X = vectors\n",
    "X_embedded = TSNE(n_components=2,n_iter=100000000).fit_transform(X)\n",
    "X_embedded.shape\n",
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=\"r\", cmap=plt.cm.Spectral)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X = vectors\n",
    "X_embedded = TSNE(n_components=2,n_iter=100000000).fit_transform(X)\n",
    "X_embedded.shape\n",
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=\"r\", cmap=plt.cm.Spectral)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "\n",
    "X = tot\n",
    "pca = decomposition.PCA(n_components=3)\n",
    "pca.fit(X)\n",
    "X = pca.transform(X)\n",
    "\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=\"r\", cmap=plt.cm.spectral,\n",
    "           edgecolor='k')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "\n",
    "X = tot\n",
    "\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(X)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = []\n",
    "g = []\n",
    "b = []  \n",
    "y = []\n",
    "\n",
    "\n",
    "r_embedded = TSNE(n_components=2,n_iter=100000000).fit_transform(X)\n",
    "r_embedded.shape\n",
    "for k in range(len(labels)):\n",
    "    if labels[k]==0:\n",
    "        r.append(X_embedded[k])\n",
    "    elif labels[k]==1:\n",
    "        g.append(X_embedded[k])\n",
    "    elif labels[k]==2:\n",
    "        b.append(X_embedded[k])\n",
    "    elif labels[k]==3:\n",
    "        y.append(X_embedded[k])\n",
    "plt.scatter([item[0] for item in r], [item[1] for item in r], c=\"r\", cmap=plt.cm.Spectral)\n",
    "plt.scatter([item[0] for item in g], [item[1] for item in g], c=\"g\", cmap=plt.cm.Spectral)\n",
    "plt.scatter([item[0] for item in b], [item[1] for item in b], c=\"b\", cmap=plt.cm.Spectral)\n",
    "plt.scatter([item[0] for item in b], [item[1] for item in b], c=\"y\", cmap=plt.cm.Spectral)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "X = tot\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "X = pca.transform(X)\n",
    "\n",
    "r = []\n",
    "r_l = []\n",
    "g = []\n",
    "g_l = []\n",
    "b = [] \n",
    "b_l = []\n",
    "y = []\n",
    "y_l = []\n",
    "\n",
    "for k in range(len(labels)):\n",
    "    if labels[k]==0:\n",
    "        r.append(X[k])\n",
    "        r_l.append(paises[k])\n",
    "    elif labels[k]==1:\n",
    "        g.append(X[k])\n",
    "        g_l.append(paises[k])\n",
    "    elif labels[k]==2:\n",
    "        b.append(X[k])\n",
    "        b_l.append(paises[k])\n",
    "    elif labels[k]==3:\n",
    "        y.append(X[k])\n",
    "        y_l.append(paises[k])\n",
    "        \n",
    "plt.scatter([item[0] for item in r], [item[1] for item in r], c=\"r\", cmap=plt.cm.Spectral)\n",
    "plt.scatter([item[0] for item in g], [item[1] for item in g], c=\"g\", cmap=plt.cm.Spectral)\n",
    "plt.scatter([item[0] for item in b], [item[1] for item in b], c=\"b\", cmap=plt.cm.Spectral)\n",
    "plt.scatter([item[0] for item in y], [item[1] for item in y], c=\"y\", cmap=plt.cm.Spectral)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (str(y_l) + '\\n')\n",
    "\n",
    "print (str(g_l) + '\\n')\n",
    "\n",
    "print (str(b_l) + '\\n')\n",
    "\n",
    "print (str(r_l) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xdata[xdata['Country Name']=='China']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.isnan(d_2016[features_d[100]]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.isnan(d_2016[features_d[1]].all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.isreal(d_2016[features_d[1]]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.isreal(np.nan).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_2016.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
